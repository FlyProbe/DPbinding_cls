{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/WS/WS2/bin/miniconda/envs/dna_binding/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/WS/WS2/bin/miniconda/envs/dna_binding/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/qiwen/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-2-117M/d064dece8a8b41d9fb8729fbe3435278786931f1/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at zhihan1996/DNABERT-2-117M were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at zhihan1996/DNABERT-2-117M and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"zhihan1996/DNABERT-2-117M\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "dna = \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"\n",
    "inputs = tokenizer(dna, return_tensors='pt')\n",
    "# Move input tensors to the same device as the model\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():  # Add this for inference to save memory\n",
    "    hidden_states = model(**inputs)[0]  # [1, sequence_length, 768]\n",
    "\n",
    "# Embedding with max pooling\n",
    "embedding_max = torch.max(hidden_states[0], dim=0)[0]\n",
    "print(embedding_max.shape)  # expect to be 768\n",
    "\n",
    "# If you need to bring it back to CPU for further processing:\n",
    "embedding_max_cpu = embedding_max.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "training_set = pd.read_csv('../dataset/train_set_v3.csv')\n",
    "test_set = pd.read_csv('../dataset/test_set_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34993 entries, 0 to 34992\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   species                34993 non-null  object\n",
      " 1   TF name                34993 non-null  object\n",
      " 2   TF sequence            34993 non-null  object\n",
      " 3   binding site sequence  34993 non-null  object\n",
      " 4   label                  34993 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3890 entries, 0 to 3889\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   species                3890 non-null   object\n",
      " 1   TF name                3890 non-null   object\n",
      " 2   TF sequence            3890 non-null   object\n",
      " 3   binding site sequence  3890 non-null   object\n",
      " 4   label                  3890 non-null   int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 152.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to generate embeddings for a DNA sequence\n",
    "def generate_embedding(sequence, tokenizer, model, device):\n",
    "    inputs = tokenizer(sequence, return_tensors='pt')\n",
    "    # Move input tensors to the same device as the model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        hidden_states = model(**inputs)[0]  # [1, sequence_length, 768]\n",
    "    \n",
    "    # Embedding with max pooling\n",
    "    embedding_max = torch.max(hidden_states[0], dim=0)[0]\n",
    "    return embedding_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 34993 sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34993 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34993/34993 [02:06<00:00, 276.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to training_set_DNA_embedding_v3.pt\n",
      "Total embeddings generated: 34993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a list to store embeddings\n",
    "embeddings_list = []\n",
    "\n",
    "# Process all sequences in training_set\n",
    "print(f\"Generating embeddings for {len(training_set)} sequences...\")\n",
    "for idx, row in tqdm(training_set.iterrows(), total=len(training_set)):\n",
    "    sequence = row['binding site sequence']\n",
    "    embedding = generate_embedding(sequence, tokenizer, model, device)\n",
    "    embeddings_list.append(embedding.cpu())  # Store on CPU to save GPU memory\n",
    "\n",
    "# Save the embeddings dictionary\n",
    "output_path = 'training_set_DNA_embedding_v3.pt'\n",
    "torch.save(embeddings_list, output_path)\n",
    "print(f\"Embeddings saved to {output_path}\")\n",
    "\n",
    "# Optional: Print some statistics\n",
    "print(f\"Total embeddings generated: {len(embeddings_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 3890 sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3890/3890 [00:13<00:00, 278.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to test_set_DNA_embedding_v3.pt\n",
      "Total embeddings generated: 3890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store embeddings\n",
    "embeddings_list_test = []\n",
    "\n",
    "# Process all sequences in training_set\n",
    "print(f\"Generating embeddings for {len(test_set)} sequences...\")\n",
    "for idx, row in tqdm(test_set.iterrows(), total=len(test_set)):\n",
    "    sequence = row['binding site sequence']\n",
    "    embedding = generate_embedding(sequence, tokenizer, model, device)\n",
    "    embeddings_list_test.append(embedding.cpu())  # Store on CPU to save GPU memory\n",
    "\n",
    "# Save the embeddings dictionary\n",
    "output_path = 'test_set_DNA_embedding_v3.pt'\n",
    "torch.save(embeddings_list_test, output_path)\n",
    "print(f\"Embeddings saved to {output_path}\")\n",
    "\n",
    "# Optional: Print some statistics\n",
    "print(f\"Total embeddings generated: {len(embeddings_list_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 35715 sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35715/35715 [01:53<00:00, 313.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to training_set_DNA_embedding_v4.pt\n",
      "Total embeddings generated: 35715\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_dna = pd.read_csv('../dataset/training_dataset_with_negatives_v4.csv')\n",
    "\n",
    "embeddings_list = []\n",
    "\n",
    "# Process all sequences in training_set\n",
    "print(f\"Generating embeddings for {len(train_dna)} sequences...\")\n",
    "for idx, row in tqdm(train_dna.iterrows(), total=len(train_dna)):\n",
    "    sequence = row['binding site sequence']\n",
    "    embedding = generate_embedding(sequence, tokenizer, model, device)\n",
    "    embeddings_list.append(embedding.cpu())  # Store on CPU to save GPU memory\n",
    "\n",
    "# Save the embeddings dictionary\n",
    "output_path = 'training_set_DNA_embedding_v4.pt'\n",
    "torch.save(embeddings_list, output_path)\n",
    "print(f\"Embeddings saved to {output_path}\")\n",
    "\n",
    "# Optional: Print some statistics\n",
    "print(f\"Total embeddings generated: {len(embeddings_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 2175 sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2175/2175 [00:06<00:00, 316.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to test_set_DNA_embedding_v4.pt\n",
      "Total embeddings generated: 2175\n"
     ]
    }
   ],
   "source": [
    "dna_test = pd.read_csv('../dataset/test_dataset_with_negatives_v4.csv')\n",
    "\n",
    "# Create a list to store embeddings\n",
    "embeddings_list_test = []\n",
    "\n",
    "# Process all sequences in training_set\n",
    "print(f\"Generating embeddings for {len(dna_test)} sequences...\")\n",
    "for idx, row in tqdm(dna_test.iterrows(), total=len(dna_test)):\n",
    "    sequence = row['binding site sequence']\n",
    "    embedding = generate_embedding(sequence, tokenizer, model, device)\n",
    "    embeddings_list_test.append(embedding.cpu())  # Store on CPU to save GPU memory\n",
    "\n",
    "# Save the embeddings dictionary\n",
    "output_path = 'test_set_DNA_embedding_v4.pt'\n",
    "torch.save(embeddings_list_test, output_path)\n",
    "print(f\"Embeddings saved to {output_path}\")\n",
    "\n",
    "# Optional: Print some statistics\n",
    "print(f\"Total embeddings generated: {len(embeddings_list_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dna_binding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
