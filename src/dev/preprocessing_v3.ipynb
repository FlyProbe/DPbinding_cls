{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb = pd.read_csv('../data_source/Factorbook-ChIP-seq.csv')\n",
    "b168 = pd.read_csv('../data_source/B.-subtilis-subtilis-168_cleaned.csv')\n",
    "collecttf = pd.read_csv('../data_source/CollectTF_cleaned.csv')\n",
    "mg1655 = pd.read_csv('../data_source/E.-coli-K-12-substr.-MG1655_cleaned_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107 entries, 0 to 106\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   species                107 non-null    object\n",
      " 1   TF name                107 non-null    object\n",
      " 2   TF sequence            107 non-null    object\n",
      " 3   binding site sequence  107 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.5+ KB\n"
     ]
    }
   ],
   "source": [
    "b168.rename(columns={'TF Sequence': 'TF sequence'}, inplace=True)\n",
    "b168.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14121 entries, 0 to 14120\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   species                11940 non-null  object\n",
      " 1   TF name                11940 non-null  object\n",
      " 2   TF sequence            11940 non-null  object\n",
      " 3   binding site sequence  11940 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 441.4+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([b168, collecttf, mg1655], ignore_index=True)\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First count the number of ambiguous nucleotides in each binding sequence\n",
    "additional_df = fb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ambiguous nucleotides\n",
    "ambiguous_nucleotides = set('RYWSKMBDHVN')\n",
    "\n",
    "# Function to count ambiguous nucleotides in a sequence\n",
    "def count_ambiguous_nucleotides(sequence):\n",
    "    return sum(1 for nucleotide in sequence if nucleotide in ambiguous_nucleotides)/len(sequence)\n",
    "\n",
    "# Apply the function to the 'binding site sequence' column\n",
    "additional_df['ambiguous_count'] = additional_df['binding site sequence'].apply(count_ambiguous_nucleotides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1021 entries, 27 to 14269\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   species                1021 non-null   object \n",
      " 1   TF name                1021 non-null   object \n",
      " 2   TF sequence            1021 non-null   object \n",
      " 3   binding site sequence  1021 non-null   object \n",
      " 4   ambiguous_count        1021 non-null   float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 47.9+ KB\n"
     ]
    }
   ],
   "source": [
    "zero_ambiguity_df = additional_df[additional_df['ambiguous_count'] <= threshold]\n",
    "zero_ambiguity_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15142 entries, 0 to 15141\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   species                12961 non-null  object \n",
      " 1   TF name                12961 non-null  object \n",
      " 2   TF sequence            12961 non-null  object \n",
      " 3   binding site sequence  12961 non-null  object \n",
      " 4   ambiguous_count        1021 non-null   float64\n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 591.6+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat([combined_df, zero_ambiguity_df], ignore_index=True)\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.drop(columns=['ambiguous_count'], inplace=True)\n",
    "combined_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12961 entries, 0 to 15141\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   species                12961 non-null  object\n",
      " 1   TF name                12961 non-null  object\n",
      " 2   TF sequence            12961 non-null  object\n",
      " 3   binding site sequence  12961 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 506.3+ KB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('../dataset/positive_set_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each individual data source, the given DNA-protein pairs are truth set. Hence the pairs not listed in the dataset can be considered as negative set. We can shuffle the pairing within each dataset (or even across different dataset) to make \"fake\" pairing, which are negative set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 12961\n",
      "Negative samples: 25922\n",
      "Total dataset size: 38883\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Create a negative set by shuffling TF sequences and binding sites across different species\n",
    "random.seed(42)  # for reproducibility\n",
    "\n",
    "# Get unique species in the dataset\n",
    "species_list = combined_df['species'].unique()\n",
    "\n",
    "# Function to generate fake pairs that don't exist in combined_df\n",
    "def generate_negative_samples(df, n_samples=10000):\n",
    "    # Create a set of existing pairs for quick lookup\n",
    "    existing_pairs = set(zip(df['TF sequence'], df['binding site sequence']))\n",
    "    \n",
    "    negative_samples = []\n",
    "    \n",
    "    # Track how many attempts we make to avoid infinite loops\n",
    "    attempts = 0\n",
    "    max_attempts = n_samples * 10\n",
    "    \n",
    "    while len(negative_samples) < n_samples and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        \n",
    "        # Pick two different species\n",
    "        species1, species2 = random.sample(list(species_list), 2)\n",
    "        \n",
    "        # Get TF from species1\n",
    "        tf_rows = df[df['species'] == species1]\n",
    "        if len(tf_rows) == 0:\n",
    "            continue\n",
    "        tf_idx = random.randint(0, len(tf_rows) - 1)\n",
    "        tf_row = tf_rows.iloc[tf_idx]\n",
    "        tf_name = tf_row['TF name']\n",
    "        tf_sequence = tf_row['TF sequence']\n",
    "        \n",
    "        # Get binding site from species2\n",
    "        bs_rows = df[df['species'] == species2]\n",
    "        if len(bs_rows) == 0:\n",
    "            continue\n",
    "        bs_idx = random.randint(0, len(bs_rows) - 1)\n",
    "        binding_site = bs_rows.iloc[bs_idx]['binding site sequence']\n",
    "        \n",
    "        # Check if this pair already exists in the positive set\n",
    "        if (tf_sequence, binding_site) not in existing_pairs:\n",
    "            negative_samples.append({\n",
    "                'species': 'fake', # fake species\n",
    "                'TF name': tf_name,\n",
    "                'TF sequence': tf_sequence,\n",
    "                'binding site sequence': binding_site,\n",
    "                'label': 0  # 0 for negative samples\n",
    "            })\n",
    "            \n",
    "            # Add to existing pairs to avoid duplicates in negative set\n",
    "            existing_pairs.add((tf_sequence, binding_site))\n",
    "    \n",
    "    return pd.DataFrame(negative_samples)\n",
    "\n",
    "# Generate negative samples\n",
    "negative_df = generate_negative_samples(combined_df, n_samples=len(combined_df)*2)\n",
    "\n",
    "# Add label column to combined_df (positive samples)\n",
    "combined_df_labeled = combined_df.copy()\n",
    "combined_df_labeled['label'] = 1  # 1 for positive samples\n",
    "\n",
    "# Combine positive and negative datasets\n",
    "final_dataset = pd.concat([combined_df_labeled, negative_df], ignore_index=True)\n",
    "\n",
    "# Shuffle the final dataset\n",
    "final_dataset = final_dataset.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Positive samples: {len(combined_df_labeled)}\")\n",
    "print(f\"Negative samples: {len(negative_df)}\")\n",
    "print(f\"Total dataset size: {len(final_dataset)}\")\n",
    "\n",
    "# Save the final dataset\n",
    "final_dataset.to_csv('../dataset/combined_dataset_with_negatives_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38883 entries, 0 to 38882\n",
      "Data columns (total 5 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   species                38883 non-null  object\n",
      " 1   TF name                38883 non-null  object\n",
      " 2   TF sequence            38883 non-null  object\n",
      " 3   binding site sequence  38883 non-null  object\n",
      " 4   label                  38883 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "final_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Division into training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 34993\n",
      "Test set size: 3890\n",
      "Training set positive examples: 11664\n",
      "Training set negative examples: 23329\n",
      "Test set positive examples: 1297\n",
      "Test set negative examples: 2593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import required libraries\n",
    "\n",
    "# Get the list of unique species from the final dataset\n",
    "species_list = final_dataset['species'].unique()\n",
    "\n",
    "# Initialize empty dataframes for train and test sets\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "# For each species, split the data into train and test sets\n",
    "# Use stratified sampling to ensure both positive and negative examples are represented\n",
    "for species in species_list:\n",
    "    species_data = final_dataset[final_dataset['species'] == species]\n",
    "    \n",
    "    # If there are fewer than 10 samples for a species, add all to training\n",
    "    if len(species_data) < 10:\n",
    "        train_df = pd.concat([train_df, species_data])\n",
    "    else:\n",
    "        # Stratified split to maintain the same ratio of positive and negative examples\n",
    "        species_train, species_test = train_test_split(\n",
    "            species_data, \n",
    "            test_size=0.1,  # 15% for testing\n",
    "            random_state=42,\n",
    "            stratify=species_data['label']  # Stratify by label\n",
    "        )\n",
    "        \n",
    "        # Add to the respective dataframes\n",
    "        train_df = pd.concat([train_df, species_train])\n",
    "        test_df = pd.concat([test_df, species_test])\n",
    "\n",
    "# Reset indices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")\n",
    "print(f\"Training set positive examples: {len(train_df[train_df['label'] == 1])}\")\n",
    "print(f\"Training set negative examples: {len(train_df[train_df['label'] == 0])}\")\n",
    "print(f\"Test set positive examples: {len(test_df[test_df['label'] == 1])}\")\n",
    "print(f\"Test set negative examples: {len(test_df[test_df['label'] == 0])}\")\n",
    "\n",
    "# Save the datasets\n",
    "train_df.to_csv('../dataset/train_set_v3.csv', index=False)\n",
    "test_df.to_csv('../dataset/test_set_v3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
