{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_dna = torch.load('../embedding/test_set_DNA_embedding_v3.pt')\n",
    "test_tf = torch.load('../embedding/test_set_tf_embedding_v3.pt')\n",
    "test_labels = pd.read_csv('../dataset/test_set_v3.csv')['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regprecise_dna_data = torch.load('regprecise/regprecise_DNA_embedding.pt')\n",
    "regprecise_tf_data = torch.load('regprecise/regprecise_tf_embedding.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DNA tensor shape: torch.Size([3890, 768])\n",
      "Test TF data shape: torch.Size([3890, 960])\n",
      "Test labels shape: torch.Size([3890])\n"
     ]
    }
   ],
   "source": [
    "# Convert test data to tensors\n",
    "test_labels_tensor = torch.tensor(test_labels.values, dtype=torch.float32)\n",
    "\n",
    "# If test_dna_data is a list, convert it to tensor\n",
    "if isinstance(test_dna, list):\n",
    "    test_feature_dim = test_dna[0].size(0)\n",
    "    test_num_samples = len(test_dna)\n",
    "    test_dna_tensor = torch.zeros((test_num_samples, test_feature_dim))\n",
    "    for i, tensor in enumerate(test_dna):\n",
    "        test_dna_tensor[i] = tensor\n",
    "else:\n",
    "    test_dna_tensor = test_dna\n",
    "\n",
    "print(f\"Test DNA tensor shape: {test_dna_tensor.shape}\")\n",
    "print(f\"Test TF data shape: {test_tf.shape}\")\n",
    "print(f\"Test labels shape: {test_labels_tensor.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DNAProteinClassifier(\n",
       "  (dna_feature_extractor): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (protein_feature_extractor): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=960, bias=True)\n",
       "    (1): LayerNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (bi_cross_attn): BiCrossAttention(\n",
       "    (dna_proj): Linear(in_features=768, out_features=960, bias=True)\n",
       "    (cross_attn_dna): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=960, out_features=960, bias=True)\n",
       "    )\n",
       "    (cross_attn_protein): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=960, out_features=960, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pool): PoolingLayer()\n",
       "  (self_attn1): SelfAttentionBlock(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1920, out_features=1920, bias=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (res_block1): ResNetBlock(\n",
       "    (fc1): Linear(in_features=1920, out_features=960, bias=True)\n",
       "    (bn1): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=960, out_features=960, bias=True)\n",
       "    (bn2): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc3): Linear(in_features=960, out_features=1920, bias=True)\n",
       "    (bn3): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (self_attn2): SelfAttentionBlock(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1920, out_features=1920, bias=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (res_block2): ResNetBlock(\n",
       "    (fc1): Linear(in_features=1920, out_features=960, bias=True)\n",
       "    (bn1): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=960, out_features=960, bias=True)\n",
       "    (bn2): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc3): Linear(in_features=960, out_features=1920, bias=True)\n",
       "    (bn3): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (self_attn3): SelfAttentionBlock(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=1920, out_features=1920, bias=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (res_block3): ResNetBlock(\n",
       "    (fc1): Linear(in_features=1920, out_features=960, bias=True)\n",
       "    (bn1): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc2): Linear(in_features=960, out_features=960, bias=True)\n",
       "    (bn2): BatchNorm1d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (fc3): Linear(in_features=960, out_features=1920, bias=True)\n",
       "    (bn3): BatchNorm1d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "  )\n",
       "  (pool3): PoolingLayer()\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1920, out_features=768, bias=True)\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=768, out_features=384, bias=True)\n",
       "    (5): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "    (8): Linear(in_features=384, out_features=96, bias=True)\n",
       "    (9): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    (10): ReLU()\n",
       "    (11): Linear(in_features=96, out_features=1, bias=True)\n",
       "    (12): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = torch.utils.data.TensorDataset(test_dna_tensor, test_tf, test_labels_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# Load the saved model\n",
    "loaded_model = model.DNAProteinClassifier()\n",
    "loaded_model = torch.load('/opt/WS/WS2/human_genome/code/binding/models_v3/dna_protein_classifier_full_v3r2.pt', weights_only=False)\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.50%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.90      0.90      2593\n",
      "         1.0       0.80      0.79      0.80      1297\n",
      "\n",
      "    accuracy                           0.87      3890\n",
      "   macro avg       0.85      0.85      0.85      3890\n",
      "weighted avg       0.86      0.87      0.86      3890\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2343  250]\n",
      " [ 275 1022]]\n",
      "\n",
      "ROC AUC Score: 0.9221\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "correct = 0\n",
    "total = 0\n",
    "predictions_all = []\n",
    "true_labels_all = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for dna_batch, protein_batch, label_batch in test_loader:\n",
    "        dna_batch, protein_batch, label_batch = dna_batch.to(device), protein_batch.to(device), label_batch.to(device)\n",
    "        outputs = loaded_model(dna_batch, protein_batch)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct += (predictions == label_batch).sum().item()\n",
    "        total += label_batch.size(0)\n",
    "        \n",
    "        # Store predictions and true labels for potential further analysis\n",
    "        predictions_all.extend(predictions.cpu().numpy())\n",
    "        true_labels_all.extend(label_batch.cpu().numpy())\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "predictions_all = np.array(predictions_all)\n",
    "true_labels_all = np.array(true_labels_all)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels_all, predictions_all))\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = confusion_matrix(true_labels_all, predictions_all)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate ROC AUC if there are both positive and negative samples\n",
    "if len(np.unique(true_labels_all)) > 1:\n",
    "    # Get raw probabilities for ROC AUC calculation\n",
    "    raw_probs = []\n",
    "    with torch.no_grad():\n",
    "        for dna_batch, protein_batch, _ in test_loader:\n",
    "            dna_batch, protein_batch = dna_batch.to(device), protein_batch.to(device)\n",
    "            outputs = loaded_model(dna_batch, protein_batch)\n",
    "            raw_probs.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    roc_auc = roc_auc_score(true_labels_all, raw_probs)\n",
    "    print(f\"\\nROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5 threshold\n",
    "# Test Accuracy: 92.78%\n",
    "\n",
    "# Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.96      0.92      0.94      1331\n",
    "#          1.0       0.88      0.94      0.91       844\n",
    "\n",
    "#     accuracy                           0.93      2175\n",
    "#    macro avg       0.92      0.93      0.92      2175\n",
    "# weighted avg       0.93      0.93      0.93      2175\n",
    "\n",
    "\n",
    "# Confusion Matrix:\n",
    "# [[1222  109]\n",
    "#  [  48  796]]\n",
    "\n",
    "# ROC AUC Score: 0.9614\n",
    "\n",
    "# 0.7 threshold\n",
    "# Test Accuracy: 93.20%\n",
    "\n",
    "# Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.93      0.94      1331\n",
    "#          1.0       0.90      0.93      0.91       844\n",
    "\n",
    "#     accuracy                           0.93      2175\n",
    "#    macro avg       0.93      0.93      0.93      2175\n",
    "# weighted avg       0.93      0.93      0.93      2175\n",
    "\n",
    "\n",
    "# Confusion Matrix:\n",
    "# [[1242   89]\n",
    "#  [  59  785]]\n",
    "\n",
    "# ROC AUC Score: 0.9614\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# 0.8 threshold\n",
    "# Test Accuracy: 93.01%\n",
    "\n",
    "# Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.94      0.94      1331\n",
    "#          1.0       0.90      0.92      0.91       844\n",
    "\n",
    "#     accuracy                           0.93      2175\n",
    "#    macro avg       0.93      0.93      0.93      2175\n",
    "# weighted avg       0.93      0.93      0.93      2175\n",
    "\n",
    "\n",
    "# Confusion Matrix:\n",
    "# [[1247   84]\n",
    "#  [  68  776]]\n",
    "\n",
    "# ROC AUC Score: 0.9614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V3r1\n",
    "# Test Accuracy: 91.93%\n",
    "\n",
    "# Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.95      0.93      0.94      2593\n",
    "#          1.0       0.86      0.91      0.88      1297\n",
    "\n",
    "#     accuracy                           0.92      3890\n",
    "#    macro avg       0.91      0.92      0.91      3890\n",
    "# weighted avg       0.92      0.92      0.92      3890\n",
    "\n",
    "\n",
    "# Confusion Matrix:\n",
    "# [[2399  194]\n",
    "#  [ 120 1177]]\n",
    "\n",
    "# ROC AUC Score: 0.9653\n",
    "\n",
    "\n",
    "\n",
    "# V4r1\n",
    "# Test Accuracy: 92.78%\n",
    "\n",
    "# Classification Report:\n",
    "#               precision    recall  f1-score   support\n",
    "\n",
    "#          0.0       0.96      0.92      0.94      1331\n",
    "#          1.0       0.88      0.94      0.91       844\n",
    "\n",
    "#     accuracy                           0.93      2175\n",
    "#    macro avg       0.92      0.93      0.92      2175\n",
    "# weighted avg       0.93      0.93      0.93      2175\n",
    "\n",
    "\n",
    "# Confusion Matrix:\n",
    "# [[1222  109]\n",
    "#  [  48  796]]\n",
    "\n",
    "# ROC AUC Score: 0.9614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and dataloader\n",
    "regprecise_test_dataset = torch.utils.data.TensorDataset(regprecise_dna_data, regprecise_tf_data)\n",
    "regprecise_test_loader = torch.utils.data.DataLoader(regprecise_test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive predictions: 16886.0\n",
      "Percentage of positive predictions: 51.35%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on regprecise_test_dataset\n",
    "regprecise_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for dna_batch, protein_batch in regprecise_test_loader:\n",
    "        dna_batch, protein_batch = dna_batch.to(device), protein_batch.to(device)\n",
    "        outputs = loaded_model(dna_batch, protein_batch)\n",
    "        regprecise_predictions.extend((outputs > 0.5).float().cpu().numpy())\n",
    "\n",
    "# Convert predictions to numpy array\n",
    "regprecise_predictions = np.array(regprecise_predictions)\n",
    "\n",
    "#Calculate the number of positive predictions\n",
    "num_positives = np.sum(regprecise_predictions)\n",
    "print(f\"Number of positive predictions: {num_positives}\")\n",
    "print(f\"Percentage of positive predictions: {num_positives / len(regprecise_predictions) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_id = pd.read_csv('/opt/WS/WS2/human_genome/code/binding/src/regprecise/tf_id.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YP_001800414.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YP_002906236.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YP_250752.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YP_225825.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NP_738273.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32880</th>\n",
       "      <td>YP_003346261.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32881</th>\n",
       "      <td>YP_002334534.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32882</th>\n",
       "      <td>YP_001305684.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32883</th>\n",
       "      <td>YP_001568035.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32884</th>\n",
       "      <td>YP_001568035.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32885 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "0      YP_001800414.1\n",
       "1      YP_002906236.1\n",
       "2         YP_250752.1\n",
       "3         YP_225825.1\n",
       "4         NP_738273.1\n",
       "...               ...\n",
       "32880  YP_003346261.1\n",
       "32881  YP_002334534.1\n",
       "32882  YP_001305684.1\n",
       "32883  YP_001568035.1\n",
       "32884  YP_001568035.1\n",
       "\n",
       "[32885 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf_id.shape[0] == regprecise_tf_data.shape[0] == regprecise_dna_data.shape[0], \"Mismatch in number of rows between tf_id and regprecise_tf_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regprecise total size: 32885\n",
      "Subset size for finetuning generation: 6577\n",
      "Total generated pairs for finetuning: 13154\n",
      "  Positive pairs: 6577\n",
      "  Negative pairs: 6577\n",
      "Finetuning training set size: 10523\n",
      "Finetuning validation set size: 2631\n",
      "Balance of positive/negative examples in combined set: 50.00% / 50.00%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, let's create indices for the split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Calculate the size of the subset for finetuning (20% of regprecise data)\n",
    "regprecise_total_size = regprecise_dna_data.shape[0]\n",
    "finetune_subset_size = int(regprecise_total_size * 0.2)\n",
    "\n",
    "# Generate random indices for the finetuning subset from regprecise data\n",
    "subset_indices = np.random.choice(regprecise_total_size, finetune_subset_size, replace=False)\n",
    "\n",
    "# Create positive pairs (original pairs from the subset)\n",
    "positive_pairs_indices = [] # Store original indices from regprecise_dna_data/regprecise_tf_data\n",
    "for i in subset_indices:\n",
    "    positive_pairs_indices.append((i, i))\n",
    "positive_labels = np.ones(len(positive_pairs_indices))\n",
    "\n",
    "# Generate negative pairs by shuffling within the subset_indices, ensuring different TFs\n",
    "negative_pairs_indices = []\n",
    "max_attempts = len(subset_indices) * 10  # Increased attempts\n",
    "attempts = 0\n",
    "\n",
    "tf_ids_in_subset = tf_id.iloc[subset_indices, 0].values\n",
    "subset_indices_list = list(range(len(subset_indices))) # Work with local indices for easier shuffling\n",
    "\n",
    "while len(negative_pairs_indices) < len(positive_pairs_indices) and attempts < max_attempts:\n",
    "    # Pick local indices within the subset\n",
    "    local_dna_idx = random.choice(subset_indices_list)\n",
    "    local_tf_idx = random.choice(subset_indices_list)\n",
    "    \n",
    "    # Convert local indices back to original regprecise indices\n",
    "    original_dna_idx = subset_indices[local_dna_idx]\n",
    "    original_tf_idx = subset_indices[local_tf_idx]\n",
    "    \n",
    "    # Ensure the TF is different by checking tf_id and not the same pair as positive\n",
    "    if original_dna_idx != original_tf_idx and tf_id.iloc[original_dna_idx, 0] != tf_id.iloc[original_tf_idx, 0]:\n",
    "        negative_pairs_indices.append((original_dna_idx, original_tf_idx))\n",
    "    attempts += 1\n",
    "\n",
    "if len(negative_pairs_indices) < len(positive_pairs_indices):\n",
    "    print(f\"Warning: Could only generate {len(negative_pairs_indices)} negative pairs, less than {len(positive_pairs_indices)} positive pairs.\")\n",
    "    # Optionally, trim positive pairs to match negative pairs count for balance\n",
    "    # positive_pairs_indices = positive_pairs_indices[:len(negative_pairs_indices)]\n",
    "    # positive_labels = positive_labels[:len(negative_pairs_indices)]\n",
    "\n",
    "negative_labels = np.zeros(len(negative_pairs_indices))\n",
    "\n",
    "# Combine positive and negative pairs' original indices\n",
    "all_pairs_original_indices = np.array(positive_pairs_indices + negative_pairs_indices)\n",
    "all_labels = np.concatenate((positive_labels, negative_labels))\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_idx = np.random.permutation(len(all_pairs_original_indices))\n",
    "all_pairs_original_indices = all_pairs_original_indices[shuffle_idx]\n",
    "all_labels = all_labels[shuffle_idx]\n",
    "\n",
    "# Create tensors for the combined dataset using original indices\n",
    "finetune_dna_all_tensor = torch.zeros((len(all_pairs_original_indices), regprecise_dna_data.shape[1]))\n",
    "finetune_tf_all_tensor = torch.zeros((len(all_pairs_original_indices), regprecise_tf_data.shape[1]))\n",
    "\n",
    "for i, (dna_idx, tf_idx) in enumerate(all_pairs_original_indices):\n",
    "    finetune_dna_all_tensor[i] = regprecise_dna_data[dna_idx]\n",
    "    finetune_tf_all_tensor[i] = regprecise_tf_data[tf_idx]\n",
    "\n",
    "finetune_labels_all_tensor = torch.tensor(all_labels, dtype=torch.float32)\n",
    "\n",
    "# Split into training and validation sets (e.g., 80% train, 20% val)\n",
    "val_split_ratio = 0.2\n",
    "num_total_samples = len(finetune_labels_all_tensor)\n",
    "num_val_samples = int(val_split_ratio * num_total_samples)\n",
    "num_train_samples = num_total_samples - num_val_samples\n",
    "\n",
    "train_indices, val_indices = train_test_split(np.arange(num_total_samples), test_size=val_split_ratio, random_state=42, stratify=all_labels)\n",
    "\n",
    "finetune_train_dna_tensor = finetune_dna_all_tensor[train_indices]\n",
    "finetune_train_tf_tensor = finetune_tf_all_tensor[train_indices]\n",
    "finetune_train_labels_tensor = finetune_labels_all_tensor[train_indices]\n",
    "\n",
    "finetune_val_dna_tensor = finetune_dna_all_tensor[val_indices]\n",
    "finetune_val_tf_tensor = finetune_tf_all_tensor[val_indices]\n",
    "finetune_val_labels_tensor = finetune_labels_all_tensor[val_indices]\n",
    "\n",
    "# Create datasets and dataloaders for finetuning\n",
    "finetune_train_dataset = torch.utils.data.TensorDataset(finetune_train_dna_tensor, finetune_train_tf_tensor, finetune_train_labels_tensor)\n",
    "finetune_train_loader = torch.utils.data.DataLoader(finetune_train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "finetune_val_dataset = torch.utils.data.TensorDataset(finetune_val_dna_tensor, finetune_val_tf_tensor, finetune_val_labels_tensor)\n",
    "finetune_val_loader = torch.utils.data.DataLoader(finetune_val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print dataset statistics\n",
    "print(f\"Regprecise total size: {regprecise_total_size}\")\n",
    "print(f\"Subset size for finetuning generation: {finetune_subset_size}\")\n",
    "print(f\"Total generated pairs for finetuning: {num_total_samples}\")\n",
    "print(f\"  Positive pairs: {len(positive_pairs_indices)}\")\n",
    "print(f\"  Negative pairs: {len(negative_pairs_indices)}\")\n",
    "print(f\"Finetuning training set size: {len(finetune_train_dataset)}\")\n",
    "print(f\"Finetuning validation set size: {len(finetune_val_dataset)}\")\n",
    "print(f\"Balance of positive/negative examples in combined set: {np.sum(all_labels)/len(all_labels)*100:.2f}% / {(1-np.sum(all_labels)/len(all_labels))*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 21,192,577 (30.46%)\n",
      "Frozen parameters: 48,382,848 (69.54%)\n"
     ]
    }
   ],
   "source": [
    "# Set the model to training mode\n",
    "loaded_model.train()\n",
    "\n",
    "# Calculate how many parameters to freeze (80% of total)\n",
    "all_params = list(loaded_model.parameters())\n",
    "total_params = len(all_params)\n",
    "params_to_freeze = int(total_params * 0.6)\n",
    "\n",
    "# Freeze the first 80% of parameters\n",
    "for i, param in enumerate(loaded_model.parameters()):\n",
    "    if i < params_to_freeze:\n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Check which parameters are trainable\n",
    "trainable_params = sum(p.numel() for p in loaded_model.parameters() if p.requires_grad)\n",
    "total_params_count = sum(p.numel() for p in loaded_model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params:,} ({trainable_params/total_params_count:.2%})\")\n",
    "print(f\"Frozen parameters: {total_params_count - trainable_params:,} ({(total_params_count - trainable_params)/total_params_count:.2%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Training Loss: 0.6340, Accuracy: 0.6335\n",
      "Validation Accuracy: 0.6043, Validation ROC AUC: 0.6766\n",
      "Saved new best model with validation accuracy: 0.6043\n",
      "--------------------------------------------------\n",
      "Epoch 2/15\n",
      "Training Loss: 0.6093, Accuracy: 0.6590\n",
      "Validation Accuracy: 0.6127, Validation ROC AUC: 0.6805\n",
      "Saved new best model with validation accuracy: 0.6127\n",
      "--------------------------------------------------\n",
      "Epoch 3/15\n",
      "Training Loss: 0.5862, Accuracy: 0.6807\n",
      "Validation Accuracy: 0.6268, Validation ROC AUC: 0.6874\n",
      "Saved new best model with validation accuracy: 0.6268\n",
      "--------------------------------------------------\n",
      "Epoch 4/15\n",
      "Training Loss: 0.5682, Accuracy: 0.7005\n",
      "Validation Accuracy: 0.6271, Validation ROC AUC: 0.6871\n",
      "Saved new best model with validation accuracy: 0.6271\n",
      "--------------------------------------------------\n",
      "Epoch 5/15\n",
      "Training Loss: 0.5492, Accuracy: 0.7172\n",
      "Validation Accuracy: 0.6287, Validation ROC AUC: 0.6918\n",
      "Saved new best model with validation accuracy: 0.6287\n",
      "--------------------------------------------------\n",
      "Epoch 6/15\n",
      "Training Loss: 0.5293, Accuracy: 0.7276\n",
      "Validation Accuracy: 0.6325, Validation ROC AUC: 0.7002\n",
      "Saved new best model with validation accuracy: 0.6325\n",
      "--------------------------------------------------\n",
      "Epoch 7/15\n",
      "Training Loss: 0.5218, Accuracy: 0.7325\n",
      "Validation Accuracy: 0.6313, Validation ROC AUC: 0.6931\n",
      "--------------------------------------------------\n",
      "Epoch 8/15\n",
      "Training Loss: 0.4967, Accuracy: 0.7566\n",
      "Validation Accuracy: 0.6351, Validation ROC AUC: 0.6969\n",
      "Saved new best model with validation accuracy: 0.6351\n",
      "--------------------------------------------------\n",
      "Epoch 9/15\n",
      "Training Loss: 0.4778, Accuracy: 0.7713\n",
      "Validation Accuracy: 0.6503, Validation ROC AUC: 0.7197\n",
      "Saved new best model with validation accuracy: 0.6503\n",
      "--------------------------------------------------\n",
      "Epoch 10/15\n",
      "Training Loss: 0.4660, Accuracy: 0.7758\n",
      "Validation Accuracy: 0.6389, Validation ROC AUC: 0.7082\n",
      "--------------------------------------------------\n",
      "Epoch 11/15\n",
      "Training Loss: 0.4535, Accuracy: 0.7864\n",
      "Validation Accuracy: 0.6309, Validation ROC AUC: 0.6985\n",
      "--------------------------------------------------\n",
      "Epoch 12/15\n",
      "Training Loss: 0.4438, Accuracy: 0.7909\n",
      "Validation Accuracy: 0.6480, Validation ROC AUC: 0.7118\n",
      "--------------------------------------------------\n",
      "Epoch 13/15\n",
      "Training Loss: 0.4214, Accuracy: 0.8037\n",
      "Validation Accuracy: 0.6423, Validation ROC AUC: 0.7070\n",
      "--------------------------------------------------\n",
      "Epoch 14/15\n",
      "Training Loss: 0.4114, Accuracy: 0.8085\n",
      "Validation Accuracy: 0.6522, Validation ROC AUC: 0.7191\n",
      "Saved new best model with validation accuracy: 0.6522\n",
      "--------------------------------------------------\n",
      "Epoch 15/15\n",
      "Training Loss: 0.3992, Accuracy: 0.8156\n",
      "Validation Accuracy: 0.6393, Validation ROC AUC: 0.7107\n",
      "--------------------------------------------------\n",
      "Fine-tuning completed! Best validation accuracy: 0.6522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define optimizer and loss function\n",
    "# Using a smaller learning rate for fine-tuning\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, loaded_model.parameters()), lr=0.0001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Fine-tuning loop\n",
    "num_epochs = 15\n",
    "best_val_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    loaded_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for dna_batch, tf_batch, labels_batch in finetune_train_loader:\n",
    "        dna_batch, tf_batch, labels_batch = dna_batch.to(device), tf_batch.to(device), labels_batch.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = loaded_model(dna_batch, tf_batch)\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate statistics\n",
    "        running_loss += loss.item() * dna_batch.size(0)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct += (predictions == labels_batch).sum().item()\n",
    "        total += labels_batch.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(finetune_train_dataset)\n",
    "    epoch_acc = correct / total\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Training Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "    \n",
    "    # Validation on finetuning validation set\n",
    "    loaded_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_raw_probs_all = []\n",
    "    val_true_labels_all = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for dna_batch, tf_batch, labels_batch in finetune_val_loader:\n",
    "            dna_batch, tf_batch, labels_batch = dna_batch.to(device), tf_batch.to(device), labels_batch.to(device)\n",
    "            outputs = loaded_model(dna_batch, tf_batch)\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            val_correct += (predictions == labels_batch).sum().item()\n",
    "            val_total += labels_batch.size(0)\n",
    "            val_raw_probs_all.extend(outputs.cpu().numpy())\n",
    "            val_true_labels_all.extend(labels_batch.cpu().numpy())\n",
    "    \n",
    "    val_acc = val_correct / val_total\n",
    "    val_roc_auc = -1.0 # Default if not calculable\n",
    "    if len(np.unique(val_true_labels_all)) > 1: # Check for both classes\n",
    "        val_roc_auc = roc_auc_score(val_true_labels_all, val_raw_probs_all)\n",
    "    \n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}, Validation ROC AUC: {val_roc_auc:.4f}\")\n",
    "    \n",
    "    # Save best model based on validation accuracy\n",
    "    if val_acc > best_val_accuracy:\n",
    "        best_val_accuracy = val_acc\n",
    "        torch.save(loaded_model, '/opt/WS/WS2/human_genome/code/binding/models_v3/dna_protein_classifier_v3_finetuned.pt')\n",
    "        print(f\"Saved new best model with validation accuracy: {best_val_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(f\"Fine-tuning completed! Best validation accuracy: {best_val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 26308\n",
      "Number of positive predictions: 18417.0\n",
      "Percentage of positive predictions: 70.01%\n",
      "\n",
      "Comparison between original and finetuned models:\n",
      "Original model positive predictions: 13495.0 (51.30%)\n",
      "Finetuned model positive predictions: 18417.0 (70.01%)\n",
      "Number of predictions that changed: 11502 (43.72%)\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model\n",
    "finetuned_model = torch.load('/opt/WS/WS2/human_genome/code/binding/models_v3/dna_protein_classifier_v3_finetuned.pt', weights_only=False)\n",
    "finetuned_model.to(device)\n",
    "finetuned_model.eval()\n",
    "\n",
    "# Get the indices that were not used in the finetuning subset\n",
    "regprecise_total_size = regprecise_dna_data.shape[0]\n",
    "\n",
    "# Get indices not used in finetuning\n",
    "test_indices = np.setdiff1d(np.arange(regprecise_total_size), subset_indices)\n",
    "print(f\"Number of test samples: {len(test_indices)}\")\n",
    "\n",
    "# Create test tensors for evaluation\n",
    "test_dna_tensor = regprecise_dna_data[test_indices]\n",
    "test_tf_tensor = regprecise_tf_data[test_indices]\n",
    "\n",
    "# Create test dataset and dataloader\n",
    "test_dataset = torch.utils.data.TensorDataset(test_dna_tensor, test_tf_tensor)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Get predictions\n",
    "predictions = []\n",
    "raw_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for dna_batch, tf_batch in test_loader:\n",
    "        dna_batch, tf_batch = dna_batch.to(device), tf_batch.to(device)\n",
    "        outputs = finetuned_model(dna_batch, tf_batch)\n",
    "        predictions.extend((outputs > 0.5).float().cpu().numpy())\n",
    "        raw_scores.extend(outputs.cpu().numpy())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "raw_scores = np.array(raw_scores)\n",
    "\n",
    "# Calculate the number of positive predictions\n",
    "num_positives = np.sum(predictions)\n",
    "print(f\"Number of positive predictions: {num_positives}\")\n",
    "print(f\"Percentage of positive predictions: {num_positives / len(predictions) * 100:.2f}%\")\n",
    "\n",
    "# Compare with original model predictions\n",
    "original_model = model.DNAProteinClassifier()\n",
    "original_model = torch.load('/opt/WS/WS2/human_genome/code/binding/models_v3/dna_protein_classifier_full_v3r2.pt', weights_only=False)\n",
    "original_model.to(device)\n",
    "original_model.eval()\n",
    "original_model.eval()\n",
    "\n",
    "original_predictions = []\n",
    "original_raw_scores = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for dna_batch, tf_batch in test_loader:\n",
    "        dna_batch, tf_batch = dna_batch.to(device), tf_batch.to(device)\n",
    "        outputs = original_model(dna_batch, tf_batch)\n",
    "        original_predictions.extend((outputs > 0.5).float().cpu().numpy())\n",
    "        original_raw_scores.extend(outputs.cpu().numpy())\n",
    "\n",
    "original_predictions = np.array(original_predictions)\n",
    "original_raw_scores = np.array(original_raw_scores)\n",
    "\n",
    "# Compare overall statistics\n",
    "orig_positives = np.sum(original_predictions)\n",
    "print(\"\\nComparison between original and finetuned models:\")\n",
    "print(f\"Original model positive predictions: {orig_positives} ({orig_positives / len(original_predictions) * 100:.2f}%)\")\n",
    "print(f\"Finetuned model positive predictions: {num_positives} ({num_positives / len(predictions) * 100:.2f}%)\")\n",
    "\n",
    "# Calculate prediction changes\n",
    "changed_predictions = np.sum(original_predictions != predictions)\n",
    "print(f\"Number of predictions that changed: {changed_predictions} ({changed_predictions / len(predictions) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
